# GitHub Actions - Build and Test Pipeline
# YAWL Workflow Engine CI/CD
#
# Optimized for Java 25 + Maven parallel builds on 16-core runners.
# Key performance decisions:
#   - Single Java 25 target (no Ant, no matrix bloat for old JVMs)
#   - maven.config supplies -T 1.5C (24 threads on 16 cores)
#   - surefire threadCount=1C with JUnit 5 native parallel execution
#   - Maven build cache enabled; ~/.m2 restored per pom.xml hash
#   - Docker, analysis, and security jobs run concurrently after build
#   - MCP/A2A agent servers launched with tuned JVM flags

name: Build and Test

on:
  push:
    branches:
      - main
      - develop
      - 'release/**'
      - 'claude/**'
  pull_request:
    branches:
      - main
      - develop
  workflow_dispatch:
    inputs:
      skip_tests:
        description: 'Skip unit tests'
        required: false
        default: 'false'
        type: boolean
      run_analysis:
        description: 'Run static analysis (SpotBugs, PMD, JaCoCo)'
        required: false
        default: 'false'
        type: boolean
  workflow_call:
    inputs:
      skip_tests:
        required: false
        default: false
        type: boolean
      run_analysis:
        required: false
        default: false
        type: boolean
    outputs:
      version:
        description: 'Build version'
        value: ${{ jobs.build.outputs.version }}
      artifact_name:
        description: 'Build artifact name'
        value: ${{ jobs.build.outputs.artifact_name }}

env:
  JAVA_VERSION: '25'
  JAVA_DISTRIBUTION: 'oracle'
  MAVEN_OPTS: '-Xms2g -Xmx8g -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=512m -XX:+UseZGC -XX:+ZGenerational -XX:+UseCompactObjectHeaders -XX:+UseAOTCache'

jobs:
  # ============================================================
  # Stage 1: Compile (fastest feedback - no tests)
  # Target: < 45 seconds wall clock
  # ============================================================
  build:
    name: Compile (Java 25, parallel -T 1.5C)
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      version: ${{ steps.version.outputs.version }}
      artifact_name: ${{ steps.version.outputs.artifact_name }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Java 25
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: ${{ env.JAVA_DISTRIBUTION }}
          cache: 'maven'

      - name: Restore Maven build cache
        uses: actions/cache@v4
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-maven-

      - name: Extract version
        id: version
        run: |
          VERSION=$(mvn -q help:evaluate -Dexpression=project.version -DforceStdout 2>/dev/null)
          echo "version=${VERSION}" >> $GITHUB_OUTPUT
          ARTIFACT="yawl-${VERSION}-$(date +%Y%m%d%H%M)"
          echo "artifact_name=${ARTIFACT}" >> $GITHUB_OUTPUT
          echo "Build: ${ARTIFACT}"

      - name: Compile (parallel)
        run: |
          START=$(date +%s%N)
          mvn -T 1.5C clean compile -DskipTests
          END=$(date +%s%N)
          MS=$(( (END - START) / 1000000 ))
          echo "compile_ms=${MS}" >> $GITHUB_STEP_SUMMARY
          echo "## Compile Time: ${MS}ms" >> $GITHUB_STEP_SUMMARY
          echo "Compile wall clock: ${MS}ms"

      - name: Package JARs/WARs (no tests)
        run: mvn -T 1.5C package -DskipTests

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.version.outputs.artifact_name }}
          path: |
            **/target/*.jar
            **/target/*.war
            !**/target/*-sources.jar
            !**/target/*-javadoc.jar
          retention-days: 7

  # ============================================================
  # Stage 2a: Unit Tests (parallel, runs concurrently with docker)
  # Target: < 45 seconds wall clock (JUnit 5 concurrent + 16 cores)
  # ============================================================
  test-unit:
    name: Unit Tests (JUnit 5 concurrent)
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: build
    if: ${{ github.event.inputs.skip_tests != 'true' }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Java 25
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: ${{ env.JAVA_DISTRIBUTION }}
          cache: 'maven'

      - name: Restore Maven cache
        uses: actions/cache@v4
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-maven-

      - name: Run unit tests (parallel, threadCount=1C)
        run: |
          START=$(date +%s%N)
          mvn -T 1.5C test \
            -Dsurefire.threadCount=1C \
            -Djunit.jupiter.execution.parallel.enabled=true \
            -Djunit.jupiter.execution.parallel.mode.default=concurrent \
            -Djunit.jupiter.execution.parallel.config.strategy=dynamic \
            -Djunit.jupiter.execution.parallel.config.dynamic.factor=1.5
          END=$(date +%s%N)
          MS=$(( (END - START) / 1000000 ))
          echo "## Test Time: ${MS}ms" >> $GITHUB_STEP_SUMMARY

      - name: Publish test results
        uses: dorny/test-reporter@v1
        if: always()
        with:
          name: Unit Test Results
          path: '**/target/surefire-reports/*.xml'
          reporter: java-junit
          fail-on-error: true

      - name: Upload surefire reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results
          path: '**/target/surefire-reports/'
          retention-days: 30

  # ============================================================
  # Stage 2b: Integration Tests (postgres service container)
  # Target: < 3 minutes (DB startup + Failsafe plugin)
  # ============================================================
  test-integration:
    name: Integration Tests (PostgreSQL)
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: build
    if: ${{ github.event.inputs.skip_tests != 'true' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop' || startsWith(github.ref, 'refs/heads/release/')) }}

    services:
      postgres:
        image: postgres:17-alpine
        env:
          POSTGRES_USER: yawl
          POSTGRES_PASSWORD: yawl
          POSTGRES_DB: yawl_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 5s
          --health-timeout 3s
          --health-retries 10

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Java 25
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: ${{ env.JAVA_DISTRIBUTION }}
          cache: 'maven'

      - name: Restore Maven cache
        uses: actions/cache@v4
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-maven-

      - name: Run integration tests
        run: |
          mvn -T 1.5C verify -P integration-test \
            -Ddatabase.type=postgresql \
            -Ddatabase.url=jdbc:postgresql://localhost:5432/yawl_test \
            -Ddatabase.username=yawl \
            -Ddatabase.password=yawl \
            -Dfailsafe.forkCount=1 \
            -Dfailsafe.reuseForks=true

      - name: Upload failsafe reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: '**/target/failsafe-reports/'
          retention-days: 30

  # ============================================================
  # Stage 2c: Static Analysis (concurrent with tests on main)
  # Target: < 4 minutes (SpotBugs + PMD + JaCoCo)
  # ============================================================
  analysis:
    name: Static Analysis + Coverage
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: build
    if: ${{ github.event.inputs.run_analysis == 'true' || github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop' }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Java 25
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: ${{ env.JAVA_DISTRIBUTION }}
          cache: 'maven'

      - name: Restore Maven cache
        uses: actions/cache@v4
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-maven-

      - name: Run analysis profile
        run: mvn -T 1.5C clean verify -P analysis

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: '**/target/site/jacoco/jacoco.xml'
          flags: unittests
          name: yawl-coverage
          fail_ci_if_error: false

      - name: Upload SpotBugs report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: spotbugs-report
          path: '**/target/spotbugsXml.xml'
          retention-days: 30

      - name: Upload PMD report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pmd-report
          path: '**/target/pmd.xml'
          retention-days: 30

  # ============================================================
  # Stage 2d: Docker Build (concurrent with tests)
  # Uses buildx bake with registry cache (mode=max)
  # Target: < 5 minutes (layer cache hit: < 2 minutes)
  # ============================================================
  docker-build:
    name: Docker Build (multi-arch buildx bake)
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: build
    if: ${{ github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop' || startsWith(github.ref, 'refs/heads/release/') }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.build.outputs.artifact_name }}

      - name: Set up QEMU (multi-arch)
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          driver-opts: |
            image=moby/buildkit:latest
            network=host

      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build all targets concurrently (bake)
        uses: docker/bake-action@v5
        with:
          files: docker-bake.hcl
          targets: production,staging
          push: ${{ github.event_name != 'pull_request' }}
          set: |
            *.cache-from=type=registry,ref=ghcr.io/yawlfoundation/yawl:buildcache
            *.cache-to=type=registry,ref=ghcr.io/yawlfoundation/yawl:buildcache,mode=max
            *.args.GIT_SHA=${{ github.sha }}
            *.args.GIT_REF=${{ github.ref_name }}

  # ============================================================
  # Stage 3: Performance Regression Gate
  # Compares compile + test times against stored baselines.
  # Fails if any stage regresses > 15%.
  # ============================================================
  perf-gate:
    name: Performance Regression Gate
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [test-unit, build]
    if: always() && needs.build.result == 'success'

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Download timing artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: '*-test-results'
          merge-multiple: true
          path: timing-artifacts/

      - name: Check regression against baseline
        run: |
          bash ci-cd/scripts/perf-regression-check.sh \
            --baseline-file ci-cd/baselines/pipeline-baseline.json \
            --threshold-pct 15 \
            --summary-file $GITHUB_STEP_SUMMARY

  # ============================================================
  # Stage 4: Pipeline Summary
  # ============================================================
  pipeline-summary:
    name: Pipeline Summary
    runs-on: ubuntu-latest
    needs: [build, test-unit, test-integration, analysis, docker-build, perf-gate]
    if: always()

    steps:
      - name: Write summary
        run: |
          echo "## YAWL CI/CD Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Stage | Status | Target |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Compile (Java 25) | ${{ needs.build.result }} | <45s |" >> $GITHUB_STEP_SUMMARY
          echo "| Unit Tests | ${{ needs.test-unit.result }} | <45s |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ needs.test-integration.result }} | <3min |" >> $GITHUB_STEP_SUMMARY
          echo "| Static Analysis | ${{ needs.analysis.result }} | <4min |" >> $GITHUB_STEP_SUMMARY
          echo "| Docker Build | ${{ needs.docker-build.result }} | <5min |" >> $GITHUB_STEP_SUMMARY
          echo "| Perf Gate | ${{ needs.perf-gate.result }} | <15% regression |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Version: ${{ needs.build.outputs.version }}" >> $GITHUB_STEP_SUMMARY

      - name: Gate: fail on critical stage failure
        run: |
          if [[ "${{ needs.build.result }}" == "failure" ]]; then
            echo "CRITICAL: compile stage failed" && exit 1
          fi
          if [[ "${{ needs.test-unit.result }}" == "failure" ]]; then
            echo "CRITICAL: unit tests failed" && exit 1
          fi
          echo "All critical gates passed"
