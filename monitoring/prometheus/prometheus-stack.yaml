# =============================================================================
# YAWL v6.0.0 - Prometheus Stack Deployment
# =============================================================================
# Deploys the kube-prometheus-stack for comprehensive monitoring:
#   - Prometheus Operator
#   - Prometheus Server
#   - Alertmanager
#   - Grafana
#   - Node Exporter
#   - kube-state-metrics
#
# Prerequisites:
#   - Helm 3.x
#   - Kubernetes 1.27+
#
# Install:
#   helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
#   helm install prometheus prometheus-community/kube-prometheus-stack -n monitoring -f monitoring/prometheus/prometheus-stack.yaml
# =============================================================================

# =============================================================================
# Prometheus Configuration
# =============================================================================
prometheus:
  prometheusSpec:
    replicas: 2

    retention: 15d
    retentionSize: "50GB"

    # Storage
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: fast-ssd
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 50Gi

    # Resource limits
    resources:
      requests:
        cpu: 500m
        memory: 2Gi
      limits:
        cpu: 2000m
        memory: 4Gi

    # Service discovery
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    ruleSelectorNilUsesHelmValues: false

    # Enable features
    enableAdminAPI: true
    enableFeatures:
      - exemplar-storage
      - memory-snapshot-on-shutdown
      - new-service-discovery-manager

    # External labels for federated Prometheus
    externalLabels:
      cluster: "yawl-production"
      environment: "production"

    # Alerting configuration
    alerting:
      alertmanagers:
        - namespace: monitoring
          name: alertmanager-operated
          port: 9093
          apiVersion: v2

    # Additional scrape configs
    additionalScrapeConfigs:
      # Scrape YAWL services
      - job_name: 'yawl-services'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - yawl-prod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__

    # Rules
    additionalPrometheusRulesMap:
      yawl-rules:
        groups:
          - name: yawl.engine
            rules:
              - record: yawl:case_creation_rate_5m
                expr: rate(yawl_case_creation_total[5m])

              - record: yawl:case_completion_rate_5m
                expr: rate(yawl_case_completion_total[5m])

              - record: yawl:active_cases
                expr: yawl_active_cases_total

              - record: yawl:error_rate_5m
                expr: rate(yawl_engine_errors_total[5m])

              - alert: YAWLHighErrorRate
                expr: yawl:error_rate_5m > 0.1
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: "YAWL high error rate"
                  description: "Error rate is {{ $value | humanize }}/s"

              - alert: YAWLCaseCreationLatencyHigh
                expr: histogram_quantile(0.99, rate(yawl_case_creation_duration_seconds_bucket[5m])) > 1
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: "YAWL case creation latency high"
                  description: "p99 latency is {{ $value | humanizeDuration }}"

              - alert: YAWLDatabaseConnectionPoolExhausted
                expr: hikaricp_connections_pending > 10
                for: 3m
                labels:
                  severity: critical
                annotations:
                  summary: "Database connection pool exhausted"
                  description: "{{ $value }} pending connections"

          - name: yawl.jvm
            rules:
              - alert: YAWLJVMHeapExhausted
                expr: (jvm_memory_used_bytes{area="heap"} / jvm_memory_max_bytes{area="heap"}) > 0.9
                for: 5m
                labels:
                  severity: critical
                annotations:
                  summary: "JVM heap nearly exhausted"
                  description: "Heap usage is {{ $value | humanizePercentage }}"

              - alert: YAWLVirtualThreadsPinned
                expr: rate(jvm_threads_states_threads{state="pinned"}[5m]) > 0
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "Virtual threads are being pinned"
                  description: "Review synchronized blocks in code"

# =============================================================================
# Alertmanager Configuration
# =============================================================================
alertmanager:
  alertmanagerSpec:
    replicas: 3

    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: fast-ssd
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi

    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 512Mi

  config:
    global:
      resolve_timeout: 5m
      smtp_smarthost: 'smtp.example.com:587'
      smtp_from: 'alerts@yawl.example.com'
      smtp_require_tls: true

    route:
      group_by: ['alertname', 'namespace', 'severity']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 4h
      receiver: 'yawl-team'
      routes:
        - match:
            severity: critical
          receiver: 'yawl-critical'
          continue: true
        - match:
            severity: warning
          receiver: 'yawl-team'

    receivers:
      - name: 'yawl-team'
        slack_configs:
          - channel: '#yawl-alerts'
            send_resolved: true
            title: '{{ .Status | toUpper }}: {{ .CommonLabels.alertname }}'
            text: >-
              {{ range .Alerts }}
              *Alert:* {{ .Labels.alertname }}
              *Severity:* {{ .Labels.severity }}
              *Description:* {{ .Annotations.description }}
              *Details:*
              {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* {{ .Value }}
              {{ end }}
              {{ end }}

      - name: 'yawl-critical'
        slack_configs:
          - channel: '#yawl-critical'
            send_resolved: true
        pagerduty_configs:
          - service_key: '<pagerduty-service-key>'
            severity: critical
            description: '{{ .CommonLabels.alertname }}'

    inhibit_rules:
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        equal: ['alertname', 'namespace']

# =============================================================================
# Grafana Configuration
# =============================================================================
grafana:
  replicas: 2

  persistence:
    enabled: true
    size: 10Gi
    storageClassName: fast-ssd

  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi

  admin:
    existingSecret: grafana-admin-credentials

  # Additional data sources
  additionalDataSources:
    - name: Loki
      type: loki
      url: http://loki.monitoring.svc.cluster.local:3100
      access: proxy
      isDefault: false

    - name: Tempo
      type: tempo
      url: http://tempo.monitoring.svc.cluster.local:3100
      access: proxy
      isDefault: false

  # Dashboard providers
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'yawl'
          orgId: 1
          folder: 'YAWL'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/yawl

  # Dashboards
  dashboards:
    yawl:
      yawl-overview:
        gnetId: 1860  # Node Exporter Full
        revision: 31
        datasource: Prometheus

  # Plugins
  plugins:
    - grafana-clock-panel
    - grafana-piechart-panel
    - grafana-worldmap-panel

  # Grafana.ini configuration
  grafana.ini:
    server:
      root_url: https://grafana.yawl.example.com
    auth.github:
      enabled: true
      allow_sign_up: true
      scopes: user:email,read:org
      auth_url: https://github.com/login/oauth/authorize
      token_url: https://github.com/login/oauth/access_token
      api_url: https://api.github.com/user
      team_ids: <github-team-id>
    metrics:
      enabled: true
    alerting:
      enabled: true
      execute_alerts: true

# =============================================================================
# Node Exporter Configuration
# =============================================================================
nodeExporter:
  enabled: true

# =============================================================================
# kube-state-metrics Configuration
# =============================================================================
kubeStateMetrics:
  enabled: true

# =============================================================================
# Prometheus Operator Configuration
# =============================================================================
prometheusOperator:
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 256Mi

  # Admission webhook
  admissionWebhooks:
    enabled: true
    patch:
      enabled: true

# =============================================================================
# Default Rules
# =============================================================================
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: true
    general: true
    k8s: true
    kubeApiserver: true
    kubeApiserverAvailability: true
    kubeApiserverSLO: true
    kubelet: true
    kubeProxy: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true
