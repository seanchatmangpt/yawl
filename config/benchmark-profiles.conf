# YAWL Benchmark Profile Configuration v6.0.0-GA
# =============================================
#
# Configuration file for benchmark profiles and test selection
# Used by run-benchmarks.sh and related orchestration scripts

# Development Profile Configuration
[profile.development]
name = "Development"
description = "Quick subset of tests for development feedback"
duration = "5-10 minutes"
priority = "low"

# Test categories included
tests = [
    "jmh-basic",
    "integration-core",
    "performance-baseline"
]

# Test configurations
test_configs = [
    { name = "ConcurrencyBenchmarkSuite", iterations = 3, warmup = 2 },
    { name = "MemoryUsageProfiler", iterations = 3, warmup = 2 },
    { name = "BenchmarkRunner", iterations = 1, parallel = false },
    { name = "SimpleTest", iterations = 1, timeout = 300 }
]

# Resource constraints
resources = {
    memory = "2g",
    cpu = "2",
    timeout = "600"
}

# CI Profile Configuration
[profile.ci]
name = "CI"
description = "Comprehensive tests for CI/CD pipeline"
duration = "30-60 minutes"
priority = "medium"

# Test categories included
tests = [
    "jmh-full",
    "integration-all",
    "performance-comprehensive",
    "stress-basic"
]

# Test configurations
test_configs = [
    { name = "ConcurrencyBenchmarkSuite", iterations = 5, warmup = 3 },
    { name = "MemoryUsageProfiler", iterations = 5, warmup = 3 },
    { name = "ThreadContentionAnalyzer", iterations = 3, warmup = 2 },
    { name = "BenchmarkConfig", iterations = 2, parallel = true },
    { name = "LoadTestSuite", iterations = 1, timeout = 1800 },
    { name = "CaseCreationStressTest", iterations = 1, timeout = 900 }
]

# Resource constraints
resources = {
    memory = "4g",
    cpu = "4",
    timeout = "3600"
}

# Production Profile Configuration
[profile.production]
name = "Production"
description = "Full benchmark suite for production validation"
duration = "2-4 hours"
priority = "high"

# Test categories included
tests = [
    "jmh-extended",
    "integration-production",
    "performance-comprehensive",
    "stress-advanced",
    "chaos-engineering",
    "regression-detection"
]

# Test configurations
test_configs = [
    { name = "ConcurrencyBenchmarkSuite", iterations = 10, warmup = 5 },
    { name = "MemoryUsageProfiler", iterations = 10, warmup = 5 },
    { name = "ThreadContentionAnalyzer", iterations = 5, warmup = 3 },
    { name = "StructuredConcurrencyBenchmark", iterations = 5, warmup = 3 },
    { name = "VirtualThreadScalingBenchmarks", iterations = 5, warmup = 3 },
    { name = "A2ACommunicationBenchmarks", iterations = 5, warmup = 3 },
    { name = "MCPPerformanceBenchmarks", iterations = 5, warmup = 3 },
    { name = "ProductionTestRunner", iterations = 3, timeout = 3600 },
    { name = "MultiRegionTest", iterations = 1, timeout = 7200 },
    { name = "CaseCreationStressTest", iterations = 3, timeout = 1800 },
    { name = "LongRunningStressTest", iterations = 2, timeout = 3600 },
    { name = "ProductionWorkloadStressTest", iterations = 2, timeout = 5400 },
    { name = "ServiceChaosTest", iterations = 3, timeout = 900 },
    { name = "EnhancedChaosTest", iterations = 2, timeout = 1200 },
    { name = "HibernatePerformanceRegressionTest", iterations = 1 },
    { name = "MemoryLeakDetectionTest", iterations = 1 }
]

# Resource constraints
resources = {
    memory = "8g",
    cpu = "8",
    timeout = "14400"
}

# Custom Profile Template
[profile.custom]
name = "Custom"
description = "User-defined test selection"
duration = "variable"
priority = "user-defined"

# Test categories - override in usage
tests = []

# Test configurations - override in usage
test_configs = []

# Resource constraints
resources = {
    memory = "4g",
    cpu = "4",
    timeout = "3600"
}

# JMH Benchmark Categories
[jmh_categories]
basic = [
    "ConcurrencyBenchmarkSuite",
    "MemoryUsageProfiler",
    "ThreadContentionAnalyzer"
]

full = [
    "ConcurrencyBenchmarkSuite",
    "MemoryUsageProfiler",
    "ThreadContentionAnalyzer",
    "StructuredConcurrencyBenchmark",
    "VirtualThreadScalingBenchmarks"
]

extended = [
    "ConcurrencyBenchmarkSuite",
    "MemoryUsageProfiler",
    "ThreadContentionAnalyzer",
    "StructuredConcurrencyBenchmark",
    "VirtualThreadScalingBenchmarks",
    "A2ACommunicationBenchmarks",
    "MCPPerformanceBenchmarks",
    "IOBoundBenchmark",
    "EventLoggerBenchmark",
    "InterfaceBClientBenchmark",
    "WorkflowExecutionBenchmark"
]

# Integration Test Categories
[integration_categories]
core = [
    "BenchmarkConfig",
    "BenchmarkRunner",
    "PerformanceTest"
]

all = [
    "BenchmarkConfig",
    "BenchmarkRunner",
    "PerformanceTest",
    "A2AIntegrationBenchmark",
    "DatabaseConnectionBenchmark"
]

production = [
    "BenchmarkConfig",
    "BenchmarkRunner",
    "PerformanceTest",
    "A2AIntegrationBenchmark",
    "DatabaseConnectionBenchmark",
    "ProductionTestRunner",
    "MultiRegionTest"
]

# Performance Test Categories
[performance_categories]
baseline = [
    "EnginePerformanceBaseline",
    "SimpleTest",
    "ScalabilityTest"
]

comprehensive = [
    "EnginePerformanceBaseline",
    "SimpleTest",
    "ScalabilityTest",
    "WorkflowThroughputBenchmark",
    "LoadTestSuite"
]

# Stress Test Categories
[stress_categories]
basic = [
    "CaseCreationStressTest",
    "WorkItemFloodTest",
    "MemoryPressureTest"
]

advanced = [
    "CaseCreationStressTest",
    "WorkItemFloodTest",
    "MemoryPressureTest",
    "LongRunningStressTest",
    "MultiTenantStressTest",
    "ProductionWorkloadStressTest"
]

# Chaos Engineering Categories
[chaos_categories]
basic = [
    "ServiceChaosTest"
]

enhanced = [
    "ServiceChaosTest",
    "EnhancedChaosTest"
]

# Regression Detection Categories
[regression_categories]
performance = [
    "LatencyRegressionTest",
    "ThroughputRegressionTest",
    "MemoryRegressionTest"
]

functionality = [
    "CorrectnessRegressionTest",
    "ComplianceRegressionTest",
    "IntegrationRegressionTest"
]

comprehensive = [
    "LatencyRegressionTest",
    "ThroughputRegressionTest",
    "MemoryRegressionTest",
    "CorrectnessRegressionTest",
    "ComplianceRegressionTest",
    "IntegrationRegressionTest"
]

# JVM Configuration
[jvm_config]
default = [
    "-Xms2g",
    "-Xmx4g",
    "-XX:+UseZGC",
    "-XX:+UseCompactObjectHeaders",
    "--enable-preview",
    "-Djava.awt.headless=true"
]

production = [
    "-Xms4g",
    "-Xmx8g",
    "-XX:+UseZGC",
    "-XX:+UseCompactObjectHeaders",
    "-XX:+UseContainerSupport",
    "-XX:+UnlockExperimentalVMOptions",
    "-Djava.util.concurrent.ForkJoinPool.common.parallelism=16",
    "--enable-preview",
    "-Djava.awt.headless=true"
]

ci = [
    "-Xms2g",
    "-Xmx4g",
    "-XX:+UseZGC",
    "-XX:+UseCompactObjectHeaders",
    "--enable-preview",
    "-Djava.awt.headless=true"
]

development = [
    "-Xms1g",
    "-Xmx2g",
    "-XX:+UseZGC",
    "--enable-preview",
    "-Djava.awt.headless=true"
]

# Output Formats
[output_formats]
html = {
    extension = ".html",
    requires = ["jq", "pandoc"],
    template = "templates/benchmark-report.html"
}

json = {
    extension = ".json",
    requires = ["jq"],
    template = "templates/benchmark-report.json"
}

csv = {
    extension = ".csv",
    requires = ["jq", "csvkit"],
    template = "templates/benchmark-report.csv"
}

pdf = {
    extension = ".pdf",
    requires = ["wkhtmltopdf", "pandoc"],
    template = "templates/benchmark-report.html"
}

# Performance Thresholds
[thresholds]
latency = {
    warning = 100,
    critical = 500,
    unit = "ms"
}

throughput = {
    warning = 1000,
    critical = 500,
    unit = "ops/sec"
}

memory = {
    warning = 70,
    critical = 90,
    unit = "percent"
}

cpu = {
    warning = 70,
    critical = 90,
    unit = "percent"
}

error_rate = {
    warning = 5,
    critical = 10,
    unit = "percent"
}

# Notification Configuration
[notifications]
slack = {
    webhook_url = "",
    channel = "#alerts",
    username = "YAWL-Bot",
    timeout = 30
}

email = {
    smtp_server = "",
    smtp_port = 587,
    username = "",
    password = "",
    from = "yawl-benchmarks@example.com",
    to = [],
    timeout = 60
}

webhook = {
    url = "",
    timeout = 30,
    headers = []
}