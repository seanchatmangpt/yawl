groups:
  - name: system_alerts
    interval: 30s
    rules:
      # CPU Alerts
      - alert: HighCPUUsage
        expr: |
          (100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 80
        for: 5m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }} for the last 5 minutes"

      - alert: CriticalCPUUsage
        expr: |
          (100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 95
        for: 2m
        labels:
          severity: critical
          component: system
        annotations:
          summary: "Critical CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }}"

      # Memory Alerts
      - alert: HighMemoryUsage
        expr: |
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 5m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value }}% on {{ $labels.instance }}"

      - alert: CriticalMemoryUsage
        expr: |
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 95
        for: 2m
        labels:
          severity: critical
          component: system
        annotations:
          summary: "Critical memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value }}% on {{ $labels.instance }}"

      # Disk Space Alerts
      - alert: HighDiskUsage
        expr: |
          (node_filesystem_avail_bytes{fstype=~"ext4|xfs"} / node_filesystem_size_bytes) < 0.15
        for: 5m
        labels:
          severity: warning
          component: storage
        annotations:
          summary: "High disk usage on {{ $labels.instance }}"
          description: "Disk {{ $labels.device }} is {{ $value | humanizePercentage }} full on {{ $labels.instance }}"

      - alert: CriticalDiskUsage
        expr: |
          (node_filesystem_avail_bytes{fstype=~"ext4|xfs"} / node_filesystem_size_bytes) < 0.05
        for: 2m
        labels:
          severity: critical
          component: storage
        annotations:
          summary: "Critical disk usage on {{ $labels.instance }}"
          description: "Disk {{ $labels.device }} is {{ $value | humanizePercentage }} full on {{ $labels.instance }}"

  - name: application_alerts
    interval: 30s
    rules:
      # Service Availability
      - alert: ServiceDown
        expr: |
          up{job="application"} == 0
        for: 1m
        labels:
          severity: critical
          component: application
        annotations:
          summary: "Service {{ $labels.job }} is down on {{ $labels.instance }}"
          description: "The service has been down for more than 1 minute"

      # HTTP Error Rate
      - alert: HighErrorRate
        expr: |
          (sum(rate(http_requests_total{status=~"5.."}[5m])) by (instance) /
           sum(rate(http_requests_total[5m])) by (instance)) > 0.05
        for: 5m
        labels:
          severity: warning
          component: application
        annotations:
          summary: "High error rate on {{ $labels.instance }}"
          description: "Error rate is {{ $value | humanizePercentage }} for the last 5 minutes"

      # High Latency
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
          component: application
        annotations:
          summary: "High latency on {{ $labels.instance }}"
          description: "95th percentile latency is {{ $value }}s"

      - alert: CriticalLatency
        expr: |
          histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m])) > 5
        for: 2m
        labels:
          severity: critical
          component: application
        annotations:
          summary: "Critical latency on {{ $labels.instance }}"
          description: "99th percentile latency is {{ $value }}s"

      # Request Rate Anomaly
      - alert: RequestRateAnomaly
        expr: |
          abs(rate(http_requests_total[5m]) - avg_over_time(rate(http_requests_total[5m] offset 1h)[1h:])) >
          2 * stddev_over_time(rate(http_requests_total[5m] offset 1h)[1h:])
        for: 10m
        labels:
          severity: info
          component: application
        annotations:
          summary: "Anomalous request rate on {{ $labels.instance }}"
          description: "Request rate is {{ $value }} requests/sec"

  - name: database_alerts
    interval: 30s
    rules:
      # Database Connection Alerts
      - alert: HighDatabaseConnections
        expr: |
          pg_stat_activity_count / pg_settings_max_connections > 0.8
        for: 5m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "High database connections on {{ $labels.instance }}"
          description: "Database connection usage is {{ $value | humanizePercentage }}"

      - alert: MaxDatabaseConnections
        expr: |
          pg_stat_activity_count >= pg_settings_max_connections
        for: 2m
        labels:
          severity: critical
          component: database
        annotations:
          summary: "Maximum database connections reached on {{ $labels.instance }}"
          description: "Database is at maximum connection limit"

      # Database Lag
      - alert: DatabaseReplicationLag
        expr: |
          pg_replication_lag_seconds > 30
        for: 5m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "Database replication lag detected on {{ $labels.instance }}"
          description: "Replication lag is {{ $value }}s"

      # Database Slow Queries
      - alert: DatabaseSlowQueries
        expr: |
          rate(pg_slow_queries_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "High rate of slow queries on {{ $labels.instance }}"
          description: "Slow query rate is {{ $value }} queries/sec"

  - name: container_alerts
    interval: 30s
    rules:
      # Container Restart Alert
      - alert: ContainerRestarts
        expr: |
          increase(container_last_seen[5m]) > 0
        for: 5m
        labels:
          severity: warning
          component: container
        annotations:
          summary: "Container {{ $labels.container_name }} is restarting"
          description: "Container has restarted {{ $value }} times in the last 5 minutes"

      # Container OOM Kill
      - alert: ContainerOOMKilled
        expr: |
          increase(container_oom_events_total[5m]) > 0
        labels:
          severity: critical
          component: container
        annotations:
          summary: "Container {{ $labels.container_name }} OOM killed"
          description: "Container was killed due to out-of-memory condition"

  - name: infrastructure_alerts
    interval: 60s
    rules:
      # Disk Read/Write Error
      - alert: HighDiskIOErrors
        expr: |
          increase(node_disk_io_time_seconds_total[5m]) > 1000
        for: 5m
        labels:
          severity: warning
          component: infrastructure
        annotations:
          summary: "High disk I/O errors on {{ $labels.instance }}"
          description: "Disk I/O time is {{ $value }}s"

      # Network Issues
      - alert: HighNetworkErrors
        expr: |
          rate(node_network_receive_errs_total[5m]) > 100 or rate(node_network_transmit_errs_total[5m]) > 100
        for: 5m
        labels:
          severity: warning
          component: infrastructure
        annotations:
          summary: "High network errors on {{ $labels.instance }}"
          description: "Network error rate is {{ $value }} errors/sec"

      # Node Exporter Down
      - alert: NodeExporterDown
        expr: |
          up{job="node-exporter"} == 0
        for: 5m
        labels:
          severity: critical
          component: infrastructure
        annotations:
          summary: "Node exporter is down on {{ $labels.instance }}"
          description: "Node exporter has been unavailable for 5 minutes"

  - name: alertmanager_alerts
    interval: 30s
    rules:
      # Alertmanager Down
      - alert: AlertmanagerDown
        expr: |
          up{job="alertmanager"} == 0
        for: 2m
        labels:
          severity: critical
          component: monitoring
        annotations:
          summary: "Alertmanager is down on {{ $labels.instance }}"
          description: "Alertmanager is not responding"

      # Pending Alerts
      - alert: HighNumberOfPendingAlerts
        expr: |
          count(ALERTS{alertstate="pending"}) > 100
        for: 10m
        labels:
          severity: warning
          component: monitoring
        annotations:
          summary: "High number of pending alerts"
          description: "There are {{ $value }} pending alerts"
